{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8246b47c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Jupyter Help</summary>\n",
    "    \n",
    "Having trouble testing your work? Double-check that you have followed the steps below to write, run, save, and test your code!\n",
    "    \n",
    "[Click here for a walkthrough GIF of the steps below](https://static-assets.codecademy.com/Courses/ds-python/jupyter-help.gif)\n",
    "\n",
    "Run all initial cells to import libraries and datasets. Then follow these steps for each question:\n",
    "    \n",
    "1. Add your solution to the cell with `## YOUR SOLUTION HERE ## `.\n",
    "2. Run the cell by selecting the `Run` button or the `Shift`+`Enter` keys.\n",
    "3. Save your work by selecting the `Save` button, the `command`+`s` keys (Mac), or `control`+`s` keys (Windows).\n",
    "4. Select the `Test Work` button at the bottom left to test your work.\n",
    "\n",
    "![Screenshot of the buttons at the top of a Jupyter Notebook. The Run and Save buttons are highlighted](https://static-assets.codecademy.com/Paths/ds-python/jupyter-buttons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6158b-fd77-4c58-a702-a6ba72b9314b",
   "metadata": {},
   "source": [
    "**Setup** Run the following cell to import libraries.\n",
    "\n",
    "\n",
    "**MLP Task: Predict Hotel Cancellations Using Booking Data**\n",
    "\n",
    "In this exercise, you will use PyTorch and neural networks to predict hotel cancellations using [real-world hotel booking data](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand) from a resort hotel. \n",
    "\n",
    "The goal is to build a neural network that can predict whether a reservation will be canceled ahead of time using features like the date of the booking, the length of stay, the number of people staying, and the average daily rate.\n",
    "\n",
    "The training dataset has already been cleaned and pre-processed. It is loaded into PyTorch dataset objects `train_dataset` and `train_loader` for batching and placed onto the GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951fc31b-4994-4030-b431-5a724b92b62d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "setup"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Training Features: 155\n",
      "\n",
      "Training Target Distribution:\n",
      "             count   pct\n",
      "is_canceled             \n",
      "0             8898  50.0\n",
      "1             8898  50.0\n",
      "\n",
      "Training size: torch.Size([17796, 1])\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load Training + Testing data\n",
    "TRAIN_CSV = \"datasets/bookings_train.csv\"\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# Training Features + Target Distribution\n",
    "TARGET = \"is_canceled\"\n",
    "train_features = [x for x in train_df.columns if x not in TARGET]\n",
    "print(\"# of Training Features:\", len(train_features))\n",
    "print()\n",
    "\n",
    "print(\"Training Target Distribution:\")\n",
    "print(train_df[TARGET].value_counts().to_frame(\"count\").assign(pct=lambda x: (x[\"count\"] / x[\"count\"].sum() * 100).round(2)))\n",
    "print()\n",
    "\n",
    "# Train + Test Split (using GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train = torch.from_numpy(train_df[train_features].values).float().to(device)\n",
    "y_train = torch.from_numpy(train_df[TARGET].values).float().view(-1, 1).to(device)\n",
    "print(\"Training size:\", y_train.shape)\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "batch_size = 32  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Check device\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c74d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Checkpoint 1/3\n",
    "\n",
    "Construct a simple MLP with the following architecture.\n",
    "\n",
    "**A.** Initialize the model class with parameters for the input size, hidden layer size, and output size:\n",
    "- First fully connected layer `fc1`: input size → hidden size\n",
    "- Second fully connected layer `fc2`: hidden size → hidden size\n",
    "- Third fully connected layer `fc3`: hidden size → output output\n",
    "- \n",
    "**B.** Also initialize a ReLU activation layer `relu`.\n",
    "\n",
    "**C.** In the forward pass, apply in the following order: \n",
    "- First layer → ReLU activation → second layer → ReLU activation → third layer → output.\n",
    "\n",
    "**D.** Instantiate the model to the variable `model` with an input feature size of `155`, a hidden layer size of `360`, and an output size of `1`.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b318baec",
   "metadata": {
    "deletable": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "cp1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "        Layer (type)              Output Shape         Param #\n",
      "======================================================================\n",
      "            Linear-1                 [32, 360]          56,160\n",
      "              ReLU-2                 [32, 360]               0\n",
      "            Linear-3                 [32, 360]         129,960\n",
      "              ReLU-4                 [32, 360]               0\n",
      "            Linear-5                   [32, 1]             361\n",
      "         SimpleMLP-6                   [32, 1]               0\n",
      "======================================================================\n",
      "Total params: 186,481\n",
      "Trainable params: 186,481\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "        \n",
    "input_features = 155\n",
    "hidden_neurons = 360\n",
    "output_classes = 1\n",
    "\n",
    "model = SimpleMLP(input_features, hidden_neurons, output_classes)\n",
    "\n",
    "# Print model summary and number of parameters\n",
    "model.to(device)\n",
    "from custom_torchinfo import custom_summary\n",
    "custom_summary(model, input_size=(32,155))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172e5e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Checkpoint 2/3\n",
    "\n",
    "Let's initialize the loss function and optimizer for training using the `torch.optim` module.\n",
    "\n",
    "**A.** Create an instance of the binary cross-entropy (with logits) loss function in PyTorch and save it to the variable `loss_fn`.\n",
    "\n",
    "**B.** Create an instance of the Adam optimizer in PyTorch with a learning rate of `0.0001` and save it to the variable `optimizer`.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73ed471",
   "metadata": {
    "deletable": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "cp2"
    ]
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "torch.manual_seed(42)\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfdae87-f84c-4758-b163-b427f7b65d10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Checkpoint 3/3\n",
    "\n",
    "Now, let's create a training loop that trains the MLP on 10 epochs while keeping track of the training loss and accuracy.\n",
    "\n",
    "**A.** Train the MLP on 10 epochs by assigning the value `10` to the variable `num_epochs`.\n",
    "\n",
    "**B.** As you loop through each epoch, initialize the following variables to `0` to keep track of during training:\n",
    "- `epoch_loss`: Training loss per epoch.\n",
    "- `num_batches`: Number of batches per epoch.\n",
    "- `correct`: Number of correct predictions.\n",
    "- `total`: Total number of predictions.\n",
    "  \n",
    "**C.** Build the training section:\n",
    "- Loop through the training batch inputs and labels.\n",
    "- Within each training batch:\n",
    "  - Obtain the logits by passing the inputs through the forward pass.\n",
    "  - Compute the loss using the loss function.\n",
    "  - Update the parameters through the backward pass.\n",
    "  - Update the loss and number of batches per epoch.\n",
    "  - Convert the logits into predicted labels\n",
    "\n",
    "**D.** For each epoch, calculate the average loss and average accuracy. \n",
    "\n",
    "Print out the BCE loss and accuracy per epoch.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details.ook for more det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ddf801b",
   "metadata": {
    "deletable": false,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "cp3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], BCE Loss: 0.5398, Accuracy: 0.7315\n",
      "Epoch [2/10], BCE Loss: 0.4483, Accuracy: 0.7800\n",
      "Epoch [3/10], BCE Loss: 0.4227, Accuracy: 0.7953\n",
      "Epoch [4/10], BCE Loss: 0.4041, Accuracy: 0.8056\n",
      "Epoch [5/10], BCE Loss: 0.3856, Accuracy: 0.8175\n",
      "Epoch [6/10], BCE Loss: 0.3699, Accuracy: 0.8273\n",
      "Epoch [7/10], BCE Loss: 0.3550, Accuracy: 0.8358\n",
      "Epoch [8/10], BCE Loss: 0.3412, Accuracy: 0.8442\n",
      "Epoch [9/10], BCE Loss: 0.3288, Accuracy: 0.8520\n",
      "Epoch [10/10], BCE Loss: 0.3184, Accuracy: 0.8554\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model.train()\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        logits = model(batch_X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Convert logits to predicted labels\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).float()\n",
    "\n",
    "        # Accuracy\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    # Average metrics\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print training progress\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], BCE Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998c35d-b7cb-4773-b27e-efb17b918d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
